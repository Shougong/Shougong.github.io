<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Text Classification Using Label Names Only, A Language Model Self-Training Approach</title>
    <url>/2020/11/29/Text-Classification-Using-Label-Names-Only-A-Language-Model-Self-Training-Approach/</url>
    <content><![CDATA[<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>现阶段文本分类方法需要基于大量的人为标注数据进行训练，这种方法缺乏实际应用性不说，而人类只需要基于描述待分类类别的少数单词就可以准确分类，因为人类对这些标签具有先验知识，能理解这些标签。</p>
<p>当前文本分类方向较为前沿的是<strong>半监督文本分类方法</strong>和<strong>零次学习方法</strong>。半监督学习方法主要分为两种途径：<strong>基于增强学习的方法</strong>和<strong>基于图的方法</strong>。</p>
<p><strong>增强学习方法</strong>通常是通过产生新的例子，并对模型的预测进行正则化以范化模型性能，增强实例的方法一般采用通过反向翻译创建为真实文本序列、通过扰动或插值在模型的隐藏状态下创建。<a id="more"></a></p>
<p><strong>基于图的方法</strong>对单词、文档、标签建立文本网络，然后采用嵌入学习或图神经网络传递标签信息。</p>
<p><strong>零次学习方法</strong>通过在已知标签集上训练，并推广到未知标签集而不使用任何新的标签文档。但是这依旧需要对数据进行标注，尤其是在大规模的数据集下，仍需要标注大量的数据。</p>
<p>基于上述内容，文章研究了弱监督文本分类问题，以探索不使用标签进行分类的可能性（<strong>动机</strong>），弱监督学习方法仅基于每个类别的单词级描述对文本文档进行分类，从而避免对标签的需求。</p>
<p>在上述基础上，文章提出了LOTClass自训练语言模型，该模型仅使用每个类的标签名称在未标注数据上训练，模型主要分成以下三个步骤：</p>
<ul>
<li>使用预训练语言模型为每个类别提供一个词汇表，该表包含与标签名称语义上相关的单词。</li>
<li>语言模型会从从未标记语料库中选择高质量的类别指向性单词来训练，能从上下文单词级别的类别预测任务重捕获类别区分信息。</li>
<li>在大量未标记的数据集中，通过文档级的自训练泛化语言模型。</li>
</ul>
<h3 id="文章的主要贡献"><a href="#文章的主要贡献" class="headerlink" title="文章的主要贡献"></a>文章的主要贡献</h3><ul>
<li>提出了一种基于预训练的神经语言模型的弱监督文本分类模型LOTClass，该模型不需要任何带标签的文档，而只需每个类的标签名称。</li>
<li>提出了一种用于查找类别指示性单词的方法和一个上下文化的单词级类别预测任务，该任务可以训练LM使用上下文来预测单词的隐含类别。 经过如此训练的LM在对未标记的语料库进行自我训练后，可以很好地概括文档级别的分类。</li>
</ul>
<h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><h4 id="类别词汇表构建"><a href="#类别词汇表构建" class="headerlink" title="类别词汇表构建"></a>类别词汇表构建</h4><p>类别词汇表的构建，其核心在于如何找到大多数情况下可相互替换的单词？通常来说，这样的单词其语义是相似的。文章的做法是，使用预训练BERT的掩码语言模型来预测在大多数上下文中，什么样的单词能替代标签名称，具体的做法：</p>
<p>对于每个出现在语料库中的标签名称$x$，由BERT的encoder产生其上下文embedding向量$h\in \mathbb{R}^{h}$，然后将其送入MLM head，这会输出整个词汇表$V$层面的概率分布，这能指示每个单词出现在这个位置的可能性：<br>$$<br>p(w \mid \boldsymbol{h})=\operatorname{Softmax}\left(W_{2} \sigma\left(W_{1} \boldsymbol{h}+\boldsymbol{b}\right)\right)<br>$$<br>其中，$\sigma(\cdot)$是激活函数，$W_{1} \in \mathbb{R}^{h \times h}$，$b \in \mathbb{R}^{h}$，$W_{2} \in \mathbb{R}^{|V| \times h}$是已经由BERT的MLM对象预训练后的可学习参数。</p>
<p><img src="/2020/11/29/Text-Classification-Using-Label-Names-Only-A-Language-Model-Self-Training-Approach/image-20201027143533074.png" alt="image-20201027143533074"></p>
<p>Table 1显示了预训练MLM预测的top-words（根据$p(w \mid \boldsymbol{h})$排序），在两个不同的上下文中替换单词sports。文章对top-50的预测结果进行了观察，发现这些预测单词通常与原单词有着相似含义，因此文章使用50个单词作为阈值，以此来定义出现在语料库中的标签名称的有效替换。最后，文章按照单词可以替换语料库中标签名称的次数对预测单词进行排列，取前100个单词作为每个类别的类别词汇，并使用NLTK去除停用词以及在多个类别中出现的单词。</p>
<p><img src="/2020/11/29/Text-Classification-Using-Label-Names-Only-A-Language-Model-Self-Training-Approach/image-20201027144937729.png" alt="image-20201027144937729"></p>
<p><img src="/2020/11/29/Text-Classification-Using-Label-Names-Only-A-Language-Model-Self-Training-Approach/image-20201027145010254.png" alt="image-20201027145010254"></p>
<p>Table 2、3、4显示不同数据集的类别词汇表。</p>
<h4 id="Masked-Category-Prediction"><a href="#Masked-Category-Prediction" class="headerlink" title="Masked Category Prediction"></a>Masked Category Prediction</h4><p>这部分主要是让分类模型关注于句子中的类别指向性单词，也就是前面说的第二步，捕获类别区分信息。一种比较直接的做法是直接高亮语料库中所有出现在类别词汇表中的单词，但是这存在两个问题：（1）单词的意思与上下文相关，出现在句子中的类别关键词不一定指向类别；（2）类别词汇表的的覆盖率是有限的，有些词项在特定上下文下雨类别关键词有着相似的含义，但是并不存在于类别词汇表中。</p>
<p>所以要让模型更好地关注类别指向性单词，就得解决这两个问题，因此文章提出了Masked Category Prediction任务，如图1所示。</p>
<p><img src="/2020/11/29/Text-Classification-Using-Label-Names-Only-A-Language-Model-Self-Training-Approach/image-20201027155224495.png" alt="image-20201027155224495"></p>
<p>具体做法如下，在section 3.1中，文章重用了BERT中的MLM方法，通过检查什么是有效的替代词来理解每个词的语境化含义。和前文一致，将MLM给出的top-50单词作为原始单词的有效替代，此外，如果一个单词$w$在50次里面，有超过20次出现在类别$c_{w}$的类别词汇表中，就将其视为$c_{w}$的类别指向性单词。然后通过对语料库中每个单词的检测，可以得到类别指向性单词集合和其类别标签$\mathcal{S}_{ind}$作为单词级别的监督。</p>
<p>对于每个类别指示单词$w$，文章使用$[MASK]$将其屏蔽，并且在排名靠前的$w$的上下文嵌入$h$上，通过交叉熵损失训练模型，以预测$w$的指示性类别$c_{w}$。<br>$$<br>\begin{aligned}\mathcal{L}<em>{M C P} &amp;=-\sum</em>{\left(w, c_{w}\right) \in \mathcal{S}<em>{\text {ind }}} \log p\left(c</em>{w} \mid \boldsymbol{h}<em>{w}\right) \p(c \mid \boldsymbol{h}) &amp;=\operatorname{Softmax}\left(W</em>{c} \boldsymbol{h}+\boldsymbol{b}<em>{c}\right)\end{aligned}<br>$$<br>其中，$W</em>{c} \in \mathbb{R}^{K \times h}$和$\boldsymbol{b}_{c} \in \mathbb{R}^{K}$是线性层的可学习参数（$K$是类别数目）。采用masked方式，可以使模型基于单词上下文进行推断，而不是简单的记住无上下文的类别关键词。</p>
<h4 id="Self-Training"><a href="#Self-Training" class="headerlink" title="Self-Training"></a>Self-Training</h4><p>这部分是文章将在MCP任务上训练后的模型在大量无标签数据集上进行自训练，主要有两个出发点：（1）大量的无标签数据集可以微调模型提高其泛化性能；（2）模型只使用masked在排名靠前的单词上训练预测类别，但未在$[CLS]$上进行，该token允许模型看到整个句子来预测类别（可能是考虑信息泄露带来的影响）。</p>
<p>自训练过程实质上是迭代地使用模型当前的预测值$P$来计算引导模型微调的目标分布$Q$。整个过程可以表示为$KL$散度：<br>$$<br>\mathcal{L}<em>{S T}=\mathrm{KL}(Q | P)=\sum</em>{i=1}^{N} \sum_{j=1}^{K} q_{i j} \log \frac{q_{i j}}{p_{i j}}<br>$$<br>其中，$N$是样本数目。</p>
<p>目标分布$Q$有两个选择：硬标记和软标记。硬标记以阈值$\tau$将高置信度的预测转换为一个one-hot标签，即$q_{i j}=\mathbb{1}\left(p_{i j}&gt;\tau\right)$；软标记通过增强高置信度预测来推导Q，同时通过对当前预测进行平方和归一化来降级低置信度预测：<br>$$<br>q_{i j}=\frac{p_{i j}^{2} / f_{j}}{\sum_{j^{\prime}}\left(p_{i j^{\prime}}^{2} / f_{j^{\prime}}\right)}, f_{j}=\sum_{i} p_{i j}<br>$$<br>然后再把经过MCP训练的分类器应用于每个文档的$[CLS]$进行模型预测：<br>$$<br>p_{i j}=p\left(c_{j} \mid \boldsymbol{h}<em>{d</em>{i}:[\mathrm{CLS}]}\right)<br>$$<br>文章发现，软标签策略能给出更好更稳定的结果，这是因为硬标记会将高置信度的结果直接视为ground truth，这有可能会导致错误传播；此外软标签不需要预设置阈值。</p>
<p>下面是每50个batch训练模型的算法：</p>
<img src="/2020/11/29/Text-Classification-Using-Label-Names-Only-A-Language-Model-Self-Training-Approach/image-20201027204809170.png" alt="image-20201027204809170" style="zoom:80%;">

<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><h4 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h4><p>文章选用了四个数据集：AG News、DBPedia、IMDB、Amazon，以下是各个数据集的相关信息：</p>
<p><img src="/2020/11/29/Text-Classification-Using-Label-Names-Only-A-Language-Model-Self-Training-Approach/image-20201027205039399.png" alt="image-20201027205039399"></p>
<h4 id="实验参数设定"><a href="#实验参数设定" class="headerlink" title="实验参数设定"></a>实验参数设定</h4><table>
<thead>
<tr>
<th>Parameters</th>
<th>Description</th>
<th>Value</th>
</tr>
</thead>
<tbody><tr>
<td>max_seq_length</td>
<td>最大句子长度，分别对应四个数据集</td>
<td>200，200，512，200</td>
</tr>
<tr>
<td>batch size</td>
<td>训练集划分的batch大小</td>
<td>128</td>
</tr>
<tr>
<td>$\alpha_{1}$</td>
<td>MCP过程的学习率</td>
<td>2e-5</td>
</tr>
<tr>
<td>$\alpha_{2}$</td>
<td>自训练过程的学习率</td>
<td>1e-6</td>
</tr>
</tbody></table>
<p>注：采用Adam优化算法。</p>
<h4 id="实验结果和结果分析"><a href="#实验结果和结果分析" class="headerlink" title="实验结果和结果分析"></a>实验结果和结果分析</h4><p>文章方法和baseline方法在分类上的准确率如下Table 6所示：</p>
<p><img src="/2020/11/29/Text-Classification-Using-Label-Names-Only-A-Language-Model-Self-Training-Approach/image-20201028105247646.png" alt="image-20201028105247646"></p>
<p>Table 6显示，在弱监督模型中，LOTClass性能最优，且自训练能提升模型的性能，这证明了文章提出的类别理解方法和MCP任务的有效性。</p>
<p><img src="/2020/11/29/Text-Classification-Using-Label-Names-Only-A-Language-Model-Self-Training-Approach/image-20201028112040426.png" alt="image-20201028112040426"></p>
<p>上图（a）显示了每个类的标记文档数与测试集准确率的关系，且LOTClass在每个类有48个标记文档的情况下，与Supervised BERT性能接近。图（b）显示了LOTClass在自训练阶段的损失和准确率随batches的变化情况，从损失曲线上可以看到，模型的更新间隔大概是50左右，且随着模型迭代，性能逐渐提高。图（c）显示了LOTClass和采用简单匹配的BERT之间的性能对比，结果显示简单匹配对结果无益，这可能是因为包含标签名称的文档可能和该文档的类别无关，且简单匹配会导致的噪声可能会导致模型做出高可信的错误预测，从而导致模型难以捕获正确的分类信号。这表明通过理解上下文中单词的含义来预测单词对分类结果的必要性。</p>
<p><img src="/2020/11/29/Text-Classification-Using-Label-Names-Only-A-Language-Model-Self-Training-Approach/image-20201028143504206.png" alt="image-20201028143504206"></p>
<p>Table 7显示了不同单词作为标签名称的敏感性，可以看到尽管使用不同的词作为label name，但是类别词汇表中的单词其意思都很接近，这能证明模型具有的鲁棒性。</p>
<p><img src="/2020/11/29/Text-Classification-Using-Label-Names-Only-A-Language-Model-Self-Training-Approach/image-20201028145603674.png" alt="image-20201028145603674"></p>
<p>Table 8显示了使用Glove 300d预训练embedding作为输入，得到的类别理解单词，可以看到结果中会存在语义截然不同的单词，这是因为Glove模型还是从局部上下文窗口中学习上下文无关的embedding，因此采用神经语言模型来捕捉目标词汇能更好的捕获长距离依赖和更精确的结果。</p>
<h3 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h3><ul>
<li>弱监督分类的潜在性能并没有被完全挖掘。</li>
<li>在其他NLP任务中，弱监督也有适用性。</li>
<li>弱监督分类的局限性：在一些语义含义更深的样本下，标签名称不足以教导模型正确的分类，因为样本的隐含表达超出了词级的理解程度，文章认为，对于这类样本允许模型向用户咨询的主动学习方式来改善弱监督学习是有效的。</li>
<li>与半监督学习进行联合学习。</li>
</ul>
]]></content>
      <categories>
        <category>paper notes</category>
      </categories>
      <tags>
        <tag>text classification</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop-2.10.1+ZooKeeper-3.6.2+Hbase-2.3.2+Hive-2.3.7安装</title>
    <url>/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p>记录Hadoop-2.10.1+ZooKeeper-3.6.2+Hbase-2.3.2+Hive-2.3.7安装的一次经历。</p>
<h3 id="预安装jdk1-8-0"><a href="#预安装jdk1-8-0" class="headerlink" title="预安装jdk1.8.0"></a>预安装jdk1.8.0</h3><ul>
<li>从<a href="https://www.oracle.com/java/technologies/javase-downloads.html%E4%B8%8B%E8%BD%BDjdk-8u261-linux-x64.rpm%EF%BC%8C%E8%AF%A5%E5%AE%89%E8%A3%85%E5%8C%85%E5%B7%B2%E7%BB%8F%E4%B8%8B%E8%BD%BD%E5%A5%BD%E4%BA%86%EF%BC%8C%E5%B9%B6%E5%AD%98%E4%BA%8E%E5%AE%89%E8%A3%85%E7%9B%AE%E5%BD%95%E4%B8%8B%E3%80%82">https://www.oracle.com/java/technologies/javase-downloads.html下载jdk-8u261-linux-x64.rpm，该安装包已经下载好了，并存于安装目录下。</a></li>
<li>如果本机上有别的java版本，可以采用两种方式，删除原先版本或者不安装该版本。</li>
<li>设置安装包的权限：chmod +x jdk-8u261-linux-x64.rpm</li>
<li>rpm安装jdk1.8.0_u261：rpm -ivh jdk-8u261-linux-x64.rpm</li>
<li>在命令行输入以下命令来配置java路径：<a id="more"></a></li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export JAVA_HOME=/usr/java/jdk1.8.0_261-amd64/</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br></pre></td></tr></table></figure>

<ul>
<li>然后令配置生效：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>

<ul>
<li>在命令行中输入：java -version，如果显示下面内容，则说明安装成功。</li>
</ul>
<p><img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201103195618114.png" alt="image-20201103195618114"></p>
<h3 id="单机安装"><a href="#单机安装" class="headerlink" title="单机安装"></a>单机安装</h3><h5 id="预配置当前系统"><a href="#预配置当前系统" class="headerlink" title="预配置当前系统"></a>预配置当前系统</h5><ul>
<li>关闭系统防火墙</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> close firewall</span></span><br><span class="line">systemctl stop firewalld.service</span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">disable</span> firewall when open system</span></span><br><span class="line">systemctl disable firewalld.service</span><br></pre></td></tr></table></figure>

<ul>
<li>创建软件的安装目录：mkdir /opt/modules</li>
<li>修改/etc/hostname</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo hostname hadoop01</span><br></pre></td></tr></table></figure>

<ul>
<li>修改hosts文件</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/hosts</span><br></pre></td></tr></table></figure>

<p>在其后面追加：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">192.168.58.133		hadoop01</span><br></pre></td></tr></table></figure>

<p>上面内容对应ip和hostname。</p>
<ul>
<li>生成ssh-key，实现免密登陆。</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh localhost</span><br><span class="line">ssh-keygen -t rsa -P &#x27;&#x27; -f ~/.ssh/id_rsa</span><br><span class="line">cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure>

<h5 id="安装hadoop-2-10-1"><a href="#安装hadoop-2-10-1" class="headerlink" title="安装hadoop-2.10.1"></a>安装hadoop-2.10.1</h5><ul>
<li>首先从官网下载hadoop-2.10.1：<a href="https://hadoop.apache.org/releases.html%EF%BC%8C%E5%B7%B2%E7%BB%8F%E5%9C%A8%E5%AE%89%E8%A3%85%E5%8C%85%E9%87%8C%E9%9D%A2%E4%BA%86%EF%BC%9Ahadoop-2.10.1.tar.gz">https://hadoop.apache.org/releases.html，已经在安装包里面了：hadoop-2.10.1.tar.gz</a></li>
<li>同样的，如果存在已安装的hadoop，将其卸载。</li>
<li>解压hadoop-2.10.1.tar.gz：tar -xzvf hadoop-2.10.1.tar.gz -C /opt/modules/</li>
<li>配置系统环境变量：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export HADOOP_HOME=/opt/modules/hadoop-2.10.1</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure>

<ul>
<li>令环境变量生效：source /etc/profile</li>
<li>在命令行中输入：hadoop，如果能输出下列内容，就说明配置成功：</li>
</ul>
<p><img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201103200522625.png" alt="image-20201103200522625.png"></p>
<ul>
<li>配置hadoop的环境变量，需要配置hadoop-env.sh、mapred-env.sh、yarn-env.sh三个文件，在三个文件中分别加入：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export JAVA_HOME=/usr/java/jdk1.8.0_261-amd64/</span><br></pre></td></tr></table></figure>

<ul>
<li><p>配置HDFS</p>
<ul>
<li><p>修改配置文件conf/core-site.xml，添加以下内容：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 配置hdfs的主节点, hdfs://hostname:9000 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop01:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/opt/modules/hadoop-2.10.1/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>上述配置的解析如下：</p>
<p><strong>fs.defaultFS</strong>：HDFS的默认访问路径，也是NameNode的访问地址。</p>
<p><strong>hadoop.tmp.dir</strong>：Hadoop数据文件的存放目录，该参数不配置会默认指向/tmp目录，开机重启后会消失，容易导致hadoop数据丢失。</p>
<ul>
<li>修改配置文件conf/hdfs-site.xml，加入以下内容：</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--配置HDFS的冗余度(副本数,默认是3个)--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 配置不检查权限 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- namenode数据块的物理存储位置 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/opt/modules/hadoop-2.10.1/tmp/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- datanode数据块的物理存储位置 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/opt/modules/hadoop-2.10.1/tmp/dfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>dfs.replication</strong>：文件在HDFS系统中的副本数。</p>
<p><strong>dfs.permissions</strong>：是否对用户权限进行检查。</p>
<p><strong>dfs.namenode.name.dir</strong>：NameNode节点数据在本地文件系统的存放位置。</p>
<p><strong>dfs.datanode.data.dir</strong>：DataNode节点数据在本地文件系统的存放位置。</p>
<ul>
<li>修改slaves文件，配置DataNode节点，需要将所有的节点都加进去，单机版只需要加当前机器的节点即可，内容是hostname。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hadoop01</span><br></pre></td></tr></table></figure>

<ul>
<li>配置mapred-site.xml文件，添加以下内容：</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.application.classpath<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>配置yarn-site.xml文件，添加以下内容：</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- Site specific YARN configuration properties --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 配置resourcemanager所在节点与访问端口 hostname:8032 hostname通常为master节点--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop01:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>hadoop在启动之前需要先格式化NameNode：hadoop namenode -format</p>
</li>
<li><p>在HADOOP_HOME目录下，输入：sbin/start-all.sh启动。</p>
</li>
<li><p>在命令行输入：jps，如果显示以下内容，说明启动成功：</p>
</li>
</ul>
<p><img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201103202921603.png" alt="image-20201103202921603.png"></p>
<h5 id="安装ZooKeeper-3-6-2"><a href="#安装ZooKeeper-3-6-2" class="headerlink" title="安装ZooKeeper-3.6.2"></a>安装ZooKeeper-3.6.2</h5><ul>
<li>从apache官网下载一个ZooKeeper的稳定版本<a href="https://zookeeper.apache.org/releases.html%EF%BC%8C%E8%BF%99%E9%87%8C%E4%B8%8B%E8%BD%BDapache-zookeeper-3.6.2-bin.tar.gz">https://zookeeper.apache.org/releases.html，这里下载apache-zookeeper-3.6.2-bin.tar.gz</a></li>
<li>同样的，如果存在已经安装好的zookeeper版本，就将其删除。</li>
<li>将安装包解压到对应的安装目录：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf apache-zookeeper-3.6.2-bin.tar.gz -C /opt/modules/</span><br></pre></td></tr></table></figure>

<ul>
<li>配置ZooKeeper的环境变量</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export ZOOKEEPER_HOME=/opt/modules/apache-zookeeper-3.6.2-bin</span><br><span class="line">export PATH=$PATH:$ZOOKEEPER_HOME/bin:$ZOOKEEPER_HOME/conf</span><br></pre></td></tr></table></figure>

<ul>
<li>在ZooKeeper安装目录下的conf文件夹中创建zoo.cfg文件，并在其中添加下列内容</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 基本事件单元，用来指示一个心跳的时长，以毫秒为单位，默认是2000</span><br><span class="line">tickTime&#x3D;2000</span><br><span class="line"># ZooKeeper数据文件的存储位置</span><br><span class="line">dataDir&#x3D;&#x2F;opt&#x2F;modules&#x2F;apache-zookeeper-3.6.2-bin&#x2F;data</span><br><span class="line"># ZooKeeper供客户端连接的端口，默认是2181</span><br><span class="line">clientPort&#x3D;2181</span><br></pre></td></tr></table></figure>

<ul>
<li>配置好后，进入ZooKeeper的安装目录，然后再命令行输入：bin/zkServer.sh start</li>
<li>在命令行输入下述内容，如果能连接上就说明安装zookeeper成功：bin/zkCli.sh -server localhost:2181</li>
</ul>
<h5 id="安装Hbase-2-3-2"><a href="#安装Hbase-2-3-2" class="headerlink" title="安装Hbase-2.3.2"></a>安装Hbase-2.3.2</h5><ul>
<li>从apache官网上下载hbase-2.3.2的安装包<a href="http://hbase.apache.org/downloads.html%EF%BC%8C%E5%9C%A8%E6%8F%90%E4%BE%9B%E7%9A%84%E5%AE%89%E8%A3%85%E6%96%87%E4%BB%B6%E5%A4%B9%E9%87%8C%E5%B7%B2%E7%BB%8F%E6%9C%89%E4%BA%86%EF%BC%9Ahbase-2.3.2-bin.tar.gz%E3%80%82">http://hbase.apache.org/downloads.html，在提供的安装文件夹里已经有了：hbase-2.3.2-bin.tar.gz。</a></li>
<li>将其解压到对应的安装目录：tar -xzvf hbase-2.3.2-bin.tar.gz -C /opt/modules/</li>
<li>修改Hbase安装目录conf/hbase-env.sh文件，来指定运行的zookeeper和JAVA_HOME：</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/java/jdk1.8.0_261-amd64</span><br><span class="line"><span class="built_in">export</span> HBASE_MANAGES_ZK=<span class="literal">false</span></span><br></pre></td></tr></table></figure>

<p>HBASE_MANAGES_ZK：false表示使用独立的zookeeper，true表示不使用hbase自带的zookeeper，这里设置为false，使用独立的zookeeper以方便后期维护。</p>
<ul>
<li>修改Hbase安装目录下的conf/hbase-site.xml文件，来指定Hbase和ZooKeeper的本地数据存储目录，默认是/tmp。</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Licensed to the Apache Software Foundation (ASF) under one</span></span><br><span class="line"><span class="comment"> * or more contributor license agreements.  See the NOTICE file</span></span><br><span class="line"><span class="comment"> * distributed with this work for additional information</span></span><br><span class="line"><span class="comment"> * regarding copyright ownership.  The ASF licenses this file</span></span><br><span class="line"><span class="comment"> * to you under the Apache License, Version 2.0 (the</span></span><br><span class="line"><span class="comment"> * &quot;License&quot;); you may not use this file except in compliance</span></span><br><span class="line"><span class="comment"> * with the License.  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *     http://www.apache.org/licenses/LICEANSE-2.0</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"> * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment"> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"> * See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"> * limitations under the License.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">    The following properties are set for running HBase as a single process on a</span></span><br><span class="line"><span class="comment">    developer workstation. With this configuration, HBase is running in</span></span><br><span class="line"><span class="comment">    &quot;stand-alone&quot; mode and without a distributed file system. In this mode, and</span></span><br><span class="line"><span class="comment">    without further configuration, HBase and ZooKeeper data are stored on the</span></span><br><span class="line"><span class="comment">    local filesystem, in a path under the value configured for `hbase.tmp.dir`.</span></span><br><span class="line"><span class="comment">    This value is overridden from its default value of `/tmp` because many</span></span><br><span class="line"><span class="comment">    systems clean `/tmp` on a regular basis. Instead, it points to a path within</span></span><br><span class="line"><span class="comment">    this HBase installation directory.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    Running against the `LocalFileSystem`, as opposed to a distributed</span></span><br><span class="line"><span class="comment">    filesystem, runs the risk of data integrity issues and data loss. Normally</span></span><br><span class="line"><span class="comment">    HBase will refuse to run in such an environment. Setting</span></span><br><span class="line"><span class="comment">    `hbase.unsafe.stream.capability.enforce` to `false` overrides this behavior,</span></span><br><span class="line"><span class="comment">    permitting operation. This configuration is for the developer workstation</span></span><br><span class="line"><span class="comment">    only and __should not be used in production!__</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    See also https://hbase.apache.org/book.html#standalone_dist</span></span><br><span class="line"><span class="comment">  --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 存储目录 需要与HDFS NameNode端口一致--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop01:9000/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--  zookeeper数据存放目录 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/modules/hbase-2.3.2/zkData<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- hbabse临时文件存放目录 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/modules/hbase-2.3.2/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>启动Hbase服务，在Hbase安装目录下，运行以下指令：bin/start-hbase.sh</li>
<li>启动以后，在命令行输入：jps，如果显示HMaster，则运行成功，单机模式只有一个HMaster进程。</li>
<li>停止Hbase服务：bin/stop-hbase.sh。</li>
</ul>
<h5 id="安装mysql"><a href="#安装mysql" class="headerlink" title="安装mysql"></a>安装mysql</h5><p>Hive的运行有内嵌、本地和远程模式，因为当前业务场景的问题，只需要本地模式即可，而本地模式需要依赖mysql。</p>
<ul>
<li>移除现有的mysql相关安装包：yum -y remove mysql*</li>
<li>下载mysql安装的yum release：wget <a href="http://repo.mysql.com/mysql-community-release-el7.rpm">http://repo.mysql.com/mysql-community-release-el7.rpm</a></li>
<li>使用rpm安装该依赖：rpm -ivh mysql-community-release-el7.rpm</li>
<li>使用yum安装mysql最新版本：yum -y install mysql-server</li>
<li>然后在命令行中输入下列指令，以开启mysql服务。</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl start mysqld   </span><br><span class="line">systemctl enable mysqld</span><br><span class="line">systemctl status mysqld</span><br></pre></td></tr></table></figure>

<ul>
<li>mysql刚安装好的时候，其密码是临时生成的，需要重新配置mysql的密码。</li>
</ul>
<p>通过下行指令可以得到临时生成的mysql密码，将其复制，记为temp password。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">grep &#x27;password&#x27; /var/log/mysqld.log|tail -n 1</span><br></pre></td></tr></table></figure>

<p>然后使用下行指令修改mysql密码为自己的：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysqladmin -uroot -p&quot;temp password&quot; password &quot;yours password&quot;</span><br></pre></td></tr></table></figure>

<p>使用自己的mysql登录密码登陆mysql：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysql -uroot -p&quot;yours password&quot;</span><br></pre></td></tr></table></figure>

<p>如果进入则说明登录成功：</p>
<img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201104110833100.png" alt="image-20201104110833100" style="zoom:80%;">

<ul>
<li>为了与hive联调，需要在mysql中创建一个叫做hive_db的表，用于存放Hive元数据信息，并且创建hive用户，为其赋予全局外部访问权限，下面是mysql的执行sql语句：</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> databse hive_db;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">user</span> hive <span class="keyword">IDENTIFIED</span> <span class="keyword">by</span> <span class="string">&#x27;hive&#x27;</span>;</span><br><span class="line"><span class="keyword">grant</span> <span class="keyword">all</span> <span class="keyword">privileges</span> <span class="keyword">on</span> hive_db.* <span class="keyword">to</span> hive@<span class="string">&#x27;%&#x27;</span> <span class="keyword">with</span> <span class="keyword">grant</span> <span class="keyword">option</span>;</span><br><span class="line"><span class="keyword">flush</span> <span class="keyword">privileges</span>;</span><br></pre></td></tr></table></figure>

<h5 id="安装hive-2-3-7"><a href="#安装hive-2-3-7" class="headerlink" title="安装hive-2.3.7"></a>安装hive-2.3.7</h5><p>Hive不需要安装集群模式，只需要在其中一个节点安装即可，这里选择hadoop01作为hive的安装节点。</p>
<ul>
<li>从apache官网上下载hive-2.3.7的安装包：<a href="https://mirrors.bfsu.edu.cn/apache/hive/hive-2.3.7/%EF%BC%8C%E5%9C%A8%E6%8F%90%E4%BE%9B%E7%9A%84%E5%AE%89%E8%A3%85%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%AD%E5%B7%B2%E7%BB%8F%E5%8C%85%E5%90%AB%E8%AF%A5%E5%AE%89%E8%A3%85%E5%8C%85%EF%BC%9Aapache-hive-2.3.7-bin.tar.gz%E3%80%82">https://mirrors.bfsu.edu.cn/apache/hive/hive-2.3.7/，在提供的安装文件夹中已经包含该安装包：apache-hive-2.3.7-bin.tar.gz。</a></li>
<li>解压hive安装包到/opt/modules/：tar -xzvf apache-hive-2.3.7-bin.tar.gz -C /opt/modules/</li>
<li>配置环境变量，在/etc/profile中添加以下内容：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export HIVE_HOME=/opt/modules/apache-hive-2.3.7-bin</span><br><span class="line">export PATH=$PATH:$HIVE_HOME/bin</span><br></pre></td></tr></table></figure>

<p>然后执行：source /etc/profile使得配置生效。</p>
<ul>
<li>在命令行输入：hive –version，如果能输出hive的版本信息，则说明安装成功。</li>
</ul>
<img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201104143049745.png" alt="image-20201104143049745" style="zoom:80%;">

<ul>
<li>创建hive数据仓库目录</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hadoop fs -mkdir	 /tmp</span><br><span class="line">hadoop fs -mkdir -p  /user/hive/warehouse</span><br><span class="line">hadoop fs -chmod g+w /tmp</span><br><span class="line">hadoop fs -chmod g+w /user/hive/warehouse</span><br></pre></td></tr></table></figure>

<p>/tmp：hive任务在HDFS中的缓存目录。</p>
<p>/user/hive/warehouse：hive数据仓库目录，用于存储hive创建的数据库。</p>
<p>这两个路径可以在配置文件中更改。</p>
<ul>
<li>上传java连接mysql的驱动包mysql-connector-java-8.0.22.jar到$HIVE_HOME/lib中。</li>
<li>修改hive的配置文件</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">   Licensed to the Apache Software Foundation (ASF) under one or more</span></span><br><span class="line"><span class="comment">   contributor license agreements.  See the NOTICE file distributed with</span></span><br><span class="line"><span class="comment">   this work for additional information regarding copyright ownership.</span></span><br><span class="line"><span class="comment">   The ASF licenses this file to You under the Apache License, Version 2.0</span></span><br><span class="line"><span class="comment">   (the &quot;License&quot;); you may not use this file except in compliance with</span></span><br><span class="line"><span class="comment">   the License.  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">       http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">   Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">   distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">   See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">   limitations under the License.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- WARNING!!! This file is auto generated for documentation purposes ONLY! --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- WARNING!!! Any changes you make to this file will be ignored by Hive.   --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- WARNING!!! You must make your changes in hive-site.xml instead.         --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- Hive Execution Parameters --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- mysql数据库连接信息 --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 采取本地模式存储hive元数据库 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.local<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- mysql连接地址, 此处连接本地mysql数据库, 可以更改为连接远程mysql数据库 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://localhost:3306/hive_db?createDatabaseIfNotExist=true<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 连接mysql的驱动类 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- mysql用户名 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- mysql登录密码 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>P@ssw0rd<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span>   </span><br><span class="line">  <span class="comment">&lt;!-- hive数据库在hdfs中的存放位置 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>location of default database for the warehouse<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line">  <span class="comment">&lt;!-- hive本地缓存目录 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.exec.local.scratchdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/tmp/hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Local scratch space for Hive jobs<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- hive在hdfs中的缓存目录 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.exec.scratchdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/tmp/hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>HDFS root scratch dir for Hive jobs which gets created with write all (733) permission. For each connecting user, an HDFS scratch dir: $&#123;hive.exec.scratchdir&#125;/<span class="symbol">&amp;lt;</span>username<span class="symbol">&amp;gt;</span> is created, with $&#123;hive.scratch.dir.permission&#125;.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 从远程文件系统中添加资源的本地临时目录 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.downloaded.resources.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/tmp/hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Temporary local directory for added resources in the remote file system.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- hive运行时的结构化日志目录 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.querylog.location<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/tmp/hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Location of Hive run time structured log file<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 日志功能开启时, 存储操作日志的最高级目录 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.logging.operation.log.location<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/tmp/hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Top level directory where operation logs are stored if logging functionality is enabled<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>初始化元数据库：$HIVE_HOME/bin/schematool -dbType mysql -initSchema</li>
</ul>
<img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201104145800066.png" alt="image-20201104145800066" style="zoom:80%;">

<p>输出上述信息说明初始化数据成功。</p>
<ul>
<li>然后命令行输入hive，测试能否正常运行hive。</li>
</ul>
<p><img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201104152203181.png" alt="image-20201104152203181"></p>
<p>有上述信息说明安装成功。</p>
<h5 id="hive整合hbase"><a href="#hive整合hbase" class="headerlink" title="hive整合hbase"></a>hive整合hbase</h5><p>在hive安装目录下的conf/hive-site.xml文件中添加下列内容：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 配置zookeeper集群访问地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop01:2181,hadoop02:2181,hadoop03:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 配置依赖的hbase、zookeeper的jar文件 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.aux.jars.path<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line">  file:///opt/modules/hbase-2.3.2/lib/hbase-common-2.3.2.jar,</span><br><span class="line">  file:///opt/modules/hbase-2.3.2/lib/hbase-client-2.3.2.jar,</span><br><span class="line">  file:///opt/modules/hbase-2.3.2/lib/hbase-server-2.3.2.jar,</span><br><span class="line">  file:///opt/modules/hbase-2.3.2/lib/hbase-hadoop2-compat-2.3.2.jar,</span><br><span class="line">  file:///opt/modules/hbase-2.3.2/lib/netty-all-4.0.23.Final.jar,</span><br><span class="line">  file:///opt/modules/hbase-2.3.2/lib/hbase-protocol-2.3.2.jar,</span><br><span class="line">  file:///opt/modules/apache-zookeeper-3.6.2-bin/lib/zookeeper-3.6.2.jar,</span><br><span class="line">  <span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.enable.doAs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>Setting this property to true will have HiveServer2 execute Hive operations as the user making the calls to it.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>启动hiveserver2服务：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hive --service hiveserver2 &amp;</span><br></pre></td></tr></table></figure>

<p><img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201105103548823.png" alt="image-20201105103548823"></p>
<ul>
<li>另起一个shell，这里采用beeline的方式连接hive：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">beeline</span><br><span class="line">!connect jdbc:hive2://hadoop01:10000</span><br></pre></td></tr></table></figure>

<p>如果显示下面结果就说明运行成功：</p>
<img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201105103246089.png" alt="image-20201105103246089" style="zoom:80%;">

<ul>
<li>到此，单机安装Hadoop-2.10.1+Hbase-2.3.2+Hive-2.3.7完毕，下面测试由hive直接创建hbase表：</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> hive_student(<span class="keyword">id</span> <span class="built_in">INT</span>, <span class="keyword">name</span> <span class="keyword">STRING</span>) <span class="keyword">STORED</span> <span class="keyword">BY</span> <span class="string">&#x27;org.apache.hadoop.hive.hbase.HBaseStorageHandler&#x27;</span> <span class="keyword">WITH</span> SERDEPROPERTIES (<span class="string">&quot;hbase.columns.mapping&quot;</span> = <span class="string">&quot;:key,cf1:name&quot;</span>) TBLPROPERTIES (<span class="string">&quot;hbase.table.name&quot;</span> = <span class="string">&quot;hive_student&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>如果在hiveserver2那个shell框里面显示下列结果，说明创建成功：</p>
<p><img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201105103851443.png" alt="image-20201105103851443"></p>
<p>登陆hbase的web界面，可以看到创建的数据库表：</p>
<p><img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201105103935523.png" alt="image-20201105103935523"></p>
<h3 id="伪分布式安装"><a href="#伪分布式安装" class="headerlink" title="伪分布式安装"></a>伪分布式安装</h3><p>伪分布式安装实际是在一台机子上开多进程来模拟分布式。</p>
<h5 id="预配置当前系统-1"><a href="#预配置当前系统-1" class="headerlink" title="预配置当前系统"></a>预配置当前系统</h5><ul>
<li>关闭当前机子的防火墙</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> close firewall</span></span><br><span class="line">systemctl stop firewalld.service</span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">disable</span> firewall when open system</span></span><br><span class="line">systemctl disable firewalld.service</span><br></pre></td></tr></table></figure>

<ul>
<li>在当前机子上创建软件的安装目录：mkdir /opt/modules</li>
<li>修改机子的/etc/hostname</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo hostname hadoop01</span><br></pre></td></tr></table></figure>

<ul>
<li>修改机子的hosts文件</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/hosts</span><br></pre></td></tr></table></figure>

<p>在其后面追加：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">192.168.58.133		hadoop01</span><br></pre></td></tr></table></figure>

<p>上面内容对应ip和hostname。</p>
<ul>
<li>生成ssh-key，实现免密登陆，集群配置的话需要在每台机子上执行下面的命令。</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh localhost</span><br><span class="line">ssh-keygen -t rsa -P &#x27;&#x27; -f ~/.ssh/id_rsa</span><br><span class="line">cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure>

<h5 id="安装hadoop-2-10-1-1"><a href="#安装hadoop-2-10-1-1" class="headerlink" title="安装hadoop-2.10.1"></a>安装hadoop-2.10.1</h5><ul>
<li>首先从官网下载hadoop-2.10.1：<a href="https://hadoop.apache.org/releases.html%EF%BC%8C%E5%B7%B2%E7%BB%8F%E5%9C%A8%E5%AE%89%E8%A3%85%E5%8C%85%E9%87%8C%E9%9D%A2%E4%BA%86%EF%BC%9Ahadoop-2.10.1.tar.gz">https://hadoop.apache.org/releases.html，已经在安装包里面了：hadoop-2.10.1.tar.gz</a></li>
<li>同样的，如果存在已安装的hadoop，将其卸载。</li>
<li>解压hadoop-2.10.1.tar.gz：tar -xzvf hadoop-2.10.1.tar.gz -C /opt/modules/</li>
<li>配置系统环境变量：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export HADOOP_HOME=/opt/modules/hadoop-2.10.1</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure>

<ul>
<li>令环境变量生效：source /etc/profile</li>
<li>在命令行中输入：hadoop，如果能输出下列内容，就说明配置成功：</li>
</ul>
<img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201103200522625-1606575338972.png" alt="image-20201103200522625" style="zoom: 80%;">

<ul>
<li>配置hadoop的环境变量，需要配置hadoop-env.sh、mapred-env.sh、yarn-env.sh三个文件，在三个文件中分别加入：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export JAVA_HOME=/usr/java/jdk1.8.0_261-amd64/</span><br></pre></td></tr></table></figure>

<ul>
<li><p>配置HDFS</p>
<ul>
<li><p>修改配置文件conf/core-site.xml，添加以下内容：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 配置hdfs的主节点, hdfs://hostname:9000 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop01:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/opt/modules/hadoop-2.10.1/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>上述配置的解析如下：</p>
<p><strong>fs.defaultFS</strong>：HDFS的默认访问路径，也是NameNode的访问地址。</p>
<p><strong>hadoop.tmp.dir</strong>：Hadoop数据文件的存放目录，该参数不配置会默认指向/tmp目录，开机重启后会消失，容易导致hadoop数据丢失。</p>
<ul>
<li>修改配置文件conf/hdfs-site.xml，加入以下内容：</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--配置HDFS的冗余度(副本数,默认是3个)--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 配置不检查权限 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- namenode数据块的物理存储位置 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/opt/modules/hadoop-2.10.1/tmp/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- datanode数据块的物理存储位置 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/opt/modules/hadoop-2.10.1/tmp/dfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>dfs.replication</strong>：文件在HDFS系统中的副本数。</p>
<p><strong>dfs.permissions</strong>：是否对用户权限进行检查。</p>
<p><strong>dfs.namenode.name.dir</strong>：NameNode节点数据在本地文件系统的存放位置。</p>
<p><strong>dfs.datanode.data.dir</strong>：DataNode节点数据在本地文件系统的存放位置。</p>
<ul>
<li>修改slaves文件，配置DataNode节点，需要将所有的节点都加进去，单机版只需要加当前机器的节点即可，内容是hostname。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hadoop01</span><br></pre></td></tr></table></figure>

<ul>
<li>配置mapred-site.xml文件，添加以下内容：</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.application.classpath<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>配置yarn-site.xml文件，添加以下内容：</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- Site specific YARN configuration properties --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 配置resourcemanager所在节点与访问端口 hostname:8032 hostname通常为master节点--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop01:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>hadoop在启动之前需要先格式化NameNode：hadoop namenode -format</p>
</li>
<li><p>在HADOOP_HOME目录下，输入：sbin/start-all.sh启动。</p>
</li>
<li><p>在命令行输入：jps，如果显示以下内容，说明启动成功：</p>
</li>
</ul>
<img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201103202921603-1606575345342.png" alt="image-20201103202921603" style="zoom:80%;">

<h5 id="安装ZooKeeper-3-6-2-1"><a href="#安装ZooKeeper-3-6-2-1" class="headerlink" title="安装ZooKeeper-3.6.2"></a>安装ZooKeeper-3.6.2</h5><ul>
<li>从apache官网下载一个ZooKeeper的稳定版本<a href="https://zookeeper.apache.org/releases.html%EF%BC%8C%E8%BF%99%E9%87%8C%E4%B8%8B%E8%BD%BDapache-zookeeper-3.6.2-bin.tar.gz">https://zookeeper.apache.org/releases.html，这里下载apache-zookeeper-3.6.2-bin.tar.gz</a></li>
<li>同样的，如果存在已经安装好的zookeeper版本，就将其删除。</li>
<li>将安装包解压到对应的安装目录：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf apache-zookeeper-3.6.2-bin.tar.gz -C /opt/modules/</span><br></pre></td></tr></table></figure>

<ul>
<li>配置ZooKeeper的环境变量</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export ZOOKEEPER_HOME=/opt/modules/apache-zookeeper-3.6.2-bin</span><br><span class="line">export PATH=$PATH:$ZOOKEEPER_HOME/bin:$ZOOKEEPER_HOME/conf</span><br></pre></td></tr></table></figure>

<ul>
<li><p>因为是伪分布式安装zookeeper，因此还需要配置不同进程的zoo.cfg配置文件，这里以模拟三台机子为例，hbase的伪分布式也按照此例。需要分别创建三个配置文件zoo1.cfg，zoo2.cfg，zoo3.cfg，分别对应如下配置：</p>
<p>zoo1.cfg：</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">initLimit&#x3D;10</span><br><span class="line">syncLimit&#x3D;5</span><br><span class="line"># ZooKeeper数据文件的存储位置</span><br><span class="line">dataDir&#x3D;&#x2F;opt&#x2F;modules&#x2F;apache-zookeeper-3.6.2-bin&#x2F;1.data</span><br><span class="line"># ZooKeeper供客户端连接的端口，默认是2181</span><br><span class="line">clientPort&#x3D;2181</span><br><span class="line">server.1&#x3D;192.168.58.133:20881:30881</span><br><span class="line">server.2&#x3D;192.168.58.133:20882:30882</span><br><span class="line">server.3&#x3D;192.168.58.133:20883:30883</span><br></pre></td></tr></table></figure>

<ul>
<li>zoo2.cfg：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">initLimit&#x3D;10</span><br><span class="line">syncLimit&#x3D;5</span><br><span class="line"># ZooKeeper数据文件的存储位置</span><br><span class="line">dataDir&#x3D;&#x2F;opt&#x2F;modules&#x2F;apache-zookeeper-3.6.2-bin&#x2F;2.data</span><br><span class="line"># ZooKeeper供客户端连接的端口，默认是2181</span><br><span class="line">clientPort&#x3D;2181</span><br><span class="line">server.1&#x3D;192.168.58.133:20881:30881</span><br><span class="line">server.2&#x3D;192.168.58.133:20882:30882</span><br><span class="line">server.3&#x3D;192.168.58.133:20883:30883</span><br></pre></td></tr></table></figure>

<ul>
<li>zoo3.cfg：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">initLimit&#x3D;10</span><br><span class="line">syncLimit&#x3D;5</span><br><span class="line"># ZooKeeper数据文件的存储位置</span><br><span class="line">dataDir&#x3D;&#x2F;opt&#x2F;modules&#x2F;apache-zookeeper-3.6.2-bin&#x2F;3.data</span><br><span class="line"># ZooKeeper供客户端连接的端口，默认是2181</span><br><span class="line">clientPort&#x3D;2181</span><br><span class="line">server.1&#x3D;192.168.58.133:20881:30881</span><br><span class="line">server.2&#x3D;192.168.58.133:20882:30882</span><br><span class="line">server.3&#x3D;192.168.58.133:20883:30883</span><br></pre></td></tr></table></figure>

<ul>
<li>配置好后，还需要分别建立1.data、2.data、3.data数据目录，并在对应目录下分别创建1.logs、2.logs、3.logs日志目录，以及分别创建myid文件，并令其中内容分别为1，2，3。</li>
<li>配置好后，进入ZooKeeper的安装目录，然后在命令行输入：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bin/zkServer.sh start /opt/modules/apache-zookeeper-3.6.2-bin/conf/zoo1.cfg</span><br><span class="line">bin/zkServer.sh start /opt/modules/apache-zookeeper-3.6.2-bin/conf/zoo2.cfg</span><br><span class="line">bin/zkServer.sh start /opt/modules/apache-zookeeper-3.6.2-bin/conf/zoo3.cfg</span><br></pre></td></tr></table></figure>

<ul>
<li>在命令行输入下述内容以查看服务状态：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bin/zkServer.sh status /opt/modules/apache-zookeeper-3.6.2-bin/conf/zoo1.cfg</span><br><span class="line">bin/zkServer.sh status /opt/modules/apache-zookeeper-3.6.2-bin/conf/zoo2.cfg</span><br><span class="line">bin/zkServer.sh status /opt/modules/apache-zookeeper-3.6.2-bin/conf/zoo3.cfg</span><br></pre></td></tr></table></figure>

<h5 id="安装Hbase-2-3-2-1"><a href="#安装Hbase-2-3-2-1" class="headerlink" title="安装Hbase-2.3.2"></a>安装Hbase-2.3.2</h5><ul>
<li>从apache官网上下载hbase-2.3.2的安装包<a href="http://hbase.apache.org/downloads.html%EF%BC%8C%E5%9C%A8%E6%8F%90%E4%BE%9B%E7%9A%84%E5%AE%89%E8%A3%85%E6%96%87%E4%BB%B6%E5%A4%B9%E9%87%8C%E5%B7%B2%E7%BB%8F%E6%9C%89%E4%BA%86%EF%BC%9Ahbase-2.3.2-bin.tar.gz%E3%80%82">http://hbase.apache.org/downloads.html，在提供的安装文件夹里已经有了：hbase-2.3.2-bin.tar.gz。</a></li>
<li>将其解压到对应的安装目录：tar -xzvf hbase-2.3.2-bin.tar.gz -C /opt/modules/</li>
<li>修改Hbase安装目录下的conf/hbase-site.xml文件，来指定Hbase和ZooKeeper的本地数据存储目录，默认是/tmp。</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Licensed to the Apache Software Foundation (ASF) under one</span></span><br><span class="line"><span class="comment"> * or more contributor license agreements.  See the NOTICE file</span></span><br><span class="line"><span class="comment"> * distributed with this work for additional information</span></span><br><span class="line"><span class="comment"> * regarding copyright ownership.  The ASF licenses this file</span></span><br><span class="line"><span class="comment"> * to you under the Apache License, Version 2.0 (the</span></span><br><span class="line"><span class="comment"> * &quot;License&quot;); you may not use this file except in compliance</span></span><br><span class="line"><span class="comment"> * with the License.  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *     http://www.apache.org/licenses/LICEANSE-2.0</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"> * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment"> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"> * See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"> * limitations under the License.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">    The following properties are set for running HBase as a single process on a</span></span><br><span class="line"><span class="comment">    developer workstation. With this configuration, HBase is running in</span></span><br><span class="line"><span class="comment">    &quot;stand-alone&quot; mode and without a distributed file system. In this mode, and</span></span><br><span class="line"><span class="comment">    without further configuration, HBase and ZooKeeper data are stored on the</span></span><br><span class="line"><span class="comment">    local filesystem, in a path under the value configured for `hbase.tmp.dir`.</span></span><br><span class="line"><span class="comment">    This value is overridden from its default value of `/tmp` because many</span></span><br><span class="line"><span class="comment">    systems clean `/tmp` on a regular basis. Instead, it points to a path within</span></span><br><span class="line"><span class="comment">    this HBase installation directory.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    Running against the `LocalFileSystem`, as opposed to a distributed</span></span><br><span class="line"><span class="comment">    filesystem, runs the risk of data integrity issues and data loss. Normally</span></span><br><span class="line"><span class="comment">    HBase will refuse to run in such an environment. Setting</span></span><br><span class="line"><span class="comment">    `hbase.unsafe.stream.capability.enforce` to `false` overrides this behavior,</span></span><br><span class="line"><span class="comment">    permitting operation. This configuration is for the developer workstation</span></span><br><span class="line"><span class="comment">    only and __should not be used in production!__</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    See also https://hbase.apache.org/book.html#standalone_dist</span></span><br><span class="line"><span class="comment">  --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 开启分布式模式  --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- Hbase数据存储目录 需要与HDFS NameNode端口一致--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop01:9000/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 配置zookeeper监听端口 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.clientPort<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--  zookeeper数据存放目录 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/modules/hbase-2.3.2/zkData<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- hbabse临时文件存放目录 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/modules/hbase-2.3.2/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>启动Hbase服务，在Hbase安装目录下，运行以下指令：bin/start-hbase.sh</li>
<li>启动以后，在命令行输入：jps，如果显示HMaster，hregionserver则表示安装成功。</li>
</ul>
<h5 id="安装mysql-1"><a href="#安装mysql-1" class="headerlink" title="安装mysql"></a>安装mysql</h5><p>Hive的运行有内嵌、本地和远程模式，因为当前业务场景的问题，只需要本地模式即可，而本地模式需要依赖mysql。</p>
<ul>
<li>移除现有的mysql相关安装包：yum -y remove mysql*</li>
<li>下载mysql安装的yum release：wget <a href="http://repo.mysql.com/mysql-community-release-el7.rpm">http://repo.mysql.com/mysql-community-release-el7.rpm</a></li>
<li>使用rpm安装该依赖：rpm -ivh mysql-community-release-el7.rpm</li>
<li>使用yum安装mysql最新版本：yum -y install mysql-server</li>
<li>然后在命令行中输入下列指令，以开启mysql服务。</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl start mysqld   </span><br><span class="line">systemctl enable mysqld</span><br><span class="line">systemctl status mysqld</span><br></pre></td></tr></table></figure>

<ul>
<li>mysql刚安装好的时候，其密码是临时生成的，需要重新配置mysql的密码。</li>
</ul>
<p>通过下行指令可以得到临时生成的mysql密码，将其复制，记为temp password。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">grep &#x27;password&#x27; /var/log/mysqld.log|tail -n 1</span><br></pre></td></tr></table></figure>

<p>然后使用下行指令修改mysql密码为自己的：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysqladmin -uroot -p&quot;temp password&quot; password &quot;yours password&quot;</span><br></pre></td></tr></table></figure>

<p>使用自己的mysql登录密码登陆mysql：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysql -uroot -p&quot;yours password&quot;</span><br></pre></td></tr></table></figure>

<p>如果进入则说明登录成功：</p>
<img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201104110833100-1606575354542.png" alt="image-20201104110833100" style="zoom:80%;">

<ul>
<li>为了与hive联调，需要在mysql中创建一个叫做hive_db的表，用于存放Hive元数据信息，并且创建hive用户，为其赋予全局外部访问权限，下面是mysql的执行sql语句：</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> databse hive_db;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">user</span> hive <span class="keyword">IDENTIFIED</span> <span class="keyword">by</span> <span class="string">&#x27;hive&#x27;</span>;</span><br><span class="line"><span class="keyword">grant</span> <span class="keyword">all</span> <span class="keyword">privileges</span> <span class="keyword">on</span> hive_db.* <span class="keyword">to</span> hive@<span class="string">&#x27;%&#x27;</span> <span class="keyword">with</span> <span class="keyword">grant</span> <span class="keyword">option</span>;</span><br><span class="line"><span class="keyword">flush</span> <span class="keyword">privileges</span>;</span><br></pre></td></tr></table></figure>

<h5 id="安装hive-2-3-7-1"><a href="#安装hive-2-3-7-1" class="headerlink" title="安装hive-2.3.7"></a>安装hive-2.3.7</h5><p>Hive不需要安装集群模式，只需要在其中一个节点安装即可，这里选择hadoop01作为hive的安装节点。</p>
<ul>
<li>从apache官网上下载hive-2.3.7的安装包：<a href="https://mirrors.bfsu.edu.cn/apache/hive/hive-2.3.7/%EF%BC%8C%E5%9C%A8%E6%8F%90%E4%BE%9B%E7%9A%84%E5%AE%89%E8%A3%85%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%AD%E5%B7%B2%E7%BB%8F%E5%8C%85%E5%90%AB%E8%AF%A5%E5%AE%89%E8%A3%85%E5%8C%85%EF%BC%9Aapache-hive-2.3.7-bin.tar.gz%E3%80%82">https://mirrors.bfsu.edu.cn/apache/hive/hive-2.3.7/，在提供的安装文件夹中已经包含该安装包：apache-hive-2.3.7-bin.tar.gz。</a></li>
<li>解压hive安装包到/opt/modules/：tar -xzvf apache-hive-2.3.7-bin.tar.gz -C /opt/modules/</li>
<li>配置环境变量，在/etc/profile中添加以下内容：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export HIVE_HOME=/opt/modules/apache-hive-2.3.7-bin</span><br><span class="line">export PATH=$PATH:$HIVE_HOME/bin</span><br></pre></td></tr></table></figure>

<p>然后执行：source /etc/profile使得配置生效。</p>
<ul>
<li>在命令行输入：hive –version，如果能输出hive的版本信息，则说明安装成功。</li>
</ul>
<img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201104143049745-1606575357878.png" alt="image-20201104143049745" style="zoom:80%;">

<ul>
<li>创建hive数据仓库目录</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hadoop fs -mkdir	 /tmp</span><br><span class="line">hadoop fs -mkdir -p  /user/hive/warehouse</span><br><span class="line">hadoop fs -chmod g+w /tmp</span><br><span class="line">hadoop fs -chmod g+w /user/hive/warehouse</span><br></pre></td></tr></table></figure>

<p>/tmp：hive任务在HDFS中的缓存目录。</p>
<p>/user/hive/warehouse：hive数据仓库目录，用于存储hive创建的数据库。</p>
<p>这两个路径可以在配置文件中更改。</p>
<ul>
<li>上传java连接mysql的驱动包mysql-connector-java-8.0.22.jar到$HIVE_HOME/lib中。</li>
<li>修改hive的配置文件</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">   Licensed to the Apache Software Foundation (ASF) under one or more</span></span><br><span class="line"><span class="comment">   contributor license agreements.  See the NOTICE file distributed with</span></span><br><span class="line"><span class="comment">   this work for additional information regarding copyright ownership.</span></span><br><span class="line"><span class="comment">   The ASF licenses this file to You under the Apache License, Version 2.0</span></span><br><span class="line"><span class="comment">   (the &quot;License&quot;); you may not use this file except in compliance with</span></span><br><span class="line"><span class="comment">   the License.  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">       http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">   Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">   distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">   See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">   limitations under the License.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- WARNING!!! This file is auto generated for documentation purposes ONLY! --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- WARNING!!! Any changes you make to this file will be ignored by Hive.   --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- WARNING!!! You must make your changes in hive-site.xml instead.         --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- Hive Execution Parameters --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- mysql数据库连接信息 --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 采取本地模式存储hive元数据库 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.local<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- mysql连接地址, 此处连接本地mysql数据库, 可以更改为连接远程mysql数据库 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://localhost:3306/hive_db?createDatabaseIfNotExist=true<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 连接mysql的驱动类 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- mysql用户名 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- mysql登录密码 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>P@ssw0rd<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span>   </span><br><span class="line">  <span class="comment">&lt;!-- hive数据库在hdfs中的存放位置 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>location of default database for the warehouse<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line">  <span class="comment">&lt;!-- hive本地缓存目录 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.exec.local.scratchdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/tmp/hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Local scratch space for Hive jobs<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- hive在hdfs中的缓存目录 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.exec.scratchdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/tmp/hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>HDFS root scratch dir for Hive jobs which gets created with write all (733) permission. For each connecting user, an HDFS scratch dir: $&#123;hive.exec.scratchdir&#125;/<span class="symbol">&amp;lt;</span>username<span class="symbol">&amp;gt;</span> is created, with $&#123;hive.scratch.dir.permission&#125;.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 从远程文件系统中添加资源的本地临时目录 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.downloaded.resources.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/tmp/hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Temporary local directory for added resources in the remote file system.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- hive运行时的结构化日志目录 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.querylog.location<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/tmp/hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Location of Hive run time structured log file<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 日志功能开启时, 存储操作日志的最高级目录 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.logging.operation.log.location<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/tmp/hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Top level directory where operation logs are stored if logging functionality is enabled<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>初始化元数据库：$HIVE_HOME/bin/schematool -dbType mysql -initSchema</li>
</ul>
<img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201104145800066-1606575363332.png" alt="image-20201104145800066" style="zoom:80%;">

<p>输出上述信息说明初始化数据成功。</p>
<ul>
<li>然后命令行输入hive，测试能否正常运行hive。</li>
</ul>
<p><img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201104152203181.png" alt="image-20201104152203181"></p>
<p>有上述信息说明安装成功。</p>
<h5 id="hive整合hbase-1"><a href="#hive整合hbase-1" class="headerlink" title="hive整合hbase"></a>hive整合hbase</h5><p>在hive安装目录下的conf/hive-site.xml文件中添加下列内容：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 配置zookeeper集群访问地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop01:2181,hadoop02:2181,hadoop03:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 配置依赖的hbase、zookeeper的jar文件 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.aux.jars.path<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line">  file:///opt/modules/hbase-2.3.2/lib/hbase-common-2.3.2.jar,</span><br><span class="line">  file:///opt/modules/hbase-2.3.2/lib/hbase-client-2.3.2.jar,</span><br><span class="line">  file:///opt/modules/hbase-2.3.2/lib/hbase-server-2.3.2.jar,</span><br><span class="line">  file:///opt/modules/hbase-2.3.2/lib/hbase-hadoop2-compat-2.3.2.jar,</span><br><span class="line">  file:///opt/modules/hbase-2.3.2/lib/netty-all-4.0.23.Final.jar,</span><br><span class="line">  file:///opt/modules/hbase-2.3.2/lib/hbase-protocol-2.3.2.jar,</span><br><span class="line">  file:///opt/modules/apache-zookeeper-3.6.2-bin/lib/zookeeper-3.6.2.jar,</span><br><span class="line">  <span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.enable.doAs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>Setting this property to true will have HiveServer2 execute Hive operations as the user making the calls to it.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>启动hiveserver2服务：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hive --service hiveserver2 &amp;</span><br></pre></td></tr></table></figure>

<p><img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201105103548823.png" alt="image-20201105103548823"></p>
<ul>
<li>另起一个shell，这里采用beeline的方式连接hive：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">beeline</span><br><span class="line">!connect jdbc:hive2://hadoop01:10000</span><br></pre></td></tr></table></figure>

<p>如果显示下面结果就说明运行成功：</p>
<img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201105103246089-1606575370561.png" alt="image-20201105103246089" style="zoom:80%;">

<ul>
<li>到此，单机安装Hadoop-2.10.1+Hbase-2.3.2+Hive-2.3.7完毕，下面测试由hive直接创建hbase表：</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> hive_student(<span class="keyword">id</span> <span class="built_in">INT</span>, <span class="keyword">name</span> <span class="keyword">STRING</span>) <span class="keyword">STORED</span> <span class="keyword">BY</span> <span class="string">&#x27;org.apache.hadoop.hive.hbase.HBaseStorageHandler&#x27;</span> <span class="keyword">WITH</span> SERDEPROPERTIES (<span class="string">&quot;hbase.columns.mapping&quot;</span> = <span class="string">&quot;:key,cf1:name&quot;</span>) TBLPROPERTIES (<span class="string">&quot;hbase.table.name&quot;</span> = <span class="string">&quot;hive_student&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>如果在hiveserver2那个shell框里面显示下列结果，说明创建成功：</p>
<p><img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201105103851443.png" alt="image-20201105103851443"></p>
<p>登陆hbase的web界面，可以看到创建的数据库表：</p>
<p><img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201105103935523.png" alt="image-20201105103935523"></p>
<h3 id="集群安装"><a href="#集群安装" class="headerlink" title="集群安装"></a>集群安装</h3><h5 id="预配置当前系统-2"><a href="#预配置当前系统-2" class="headerlink" title="预配置当前系统"></a>预配置当前系统</h5><p>这部分配置以我本地三台虚拟机的配置为例</p>
<ul>
<li>关闭集群中每个机子的防火墙</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> close firewall</span></span><br><span class="line">systemctl stop firewalld.service</span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">disable</span> firewall when open system</span></span><br><span class="line">systemctl disable firewalld.service</span><br></pre></td></tr></table></figure>

<ul>
<li>在每台机子上创建软件的安装目录：mkdir /opt/modules</li>
<li>修改每台机子的/etc/hostname</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo hostname hadoop01</span><br></pre></td></tr></table></figure>

<p>因为有三台虚拟机，因此，hostname分别对应hadoop01、hadoop02、hadoop03</p>
<ul>
<li>修改每台机子的hosts文件</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/hosts</span><br></pre></td></tr></table></figure>

<p>在其后面追加：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">192.168.58.133		hadoop01</span><br><span class="line">192.168.58.134		hadoop02</span><br><span class="line">192.168.58.135		hadoop03</span><br></pre></td></tr></table></figure>

<p>上面内容对应ip和hostname，集群配置的话需要添加全部集群的ip和hostname，此外集群中所有机器需要保证处于同一网段下。</p>
<ul>
<li>生成ssh-key，实现免密登陆，集群配置的话需要在每台机子上执行下面的命令。</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh localhost</span><br><span class="line">ssh-keygen -t rsa -P &#x27;&#x27; -f ~/.ssh/id_rsa</span><br><span class="line">cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure>

<ul>
<li>需要将每台机子上生成的ssh-key发送到集群中的每个机器上：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd ~/.ssh/</span><br><span class="line">ssh-copy-id hadoop01</span><br><span class="line">ssh-copy-id hadoop02</span><br><span class="line">ssh-copy-id hadoop03</span><br></pre></td></tr></table></figure>

<h5 id="安装hadoop-2-10-1-2"><a href="#安装hadoop-2-10-1-2" class="headerlink" title="安装hadoop-2.10.1"></a>安装hadoop-2.10.1</h5><ul>
<li>首先从官网下载hadoop-2.10.1：<a href="https://hadoop.apache.org/releases.html%EF%BC%8C%E5%B7%B2%E7%BB%8F%E5%9C%A8%E5%AE%89%E8%A3%85%E5%8C%85%E9%87%8C%E9%9D%A2%E4%BA%86%EF%BC%9Ahadoop-2.10.1.tar.gz">https://hadoop.apache.org/releases.html，已经在安装包里面了：hadoop-2.10.1.tar.gz</a></li>
<li>同样的，如果存在已安装的hadoop，将其卸载。</li>
<li>解压hadoop-2.10.1.tar.gz：tar -xzvf hadoop-2.10.1.tar.gz -C /opt/modules/</li>
<li>配置系统环境变量：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export HADOOP_HOME=/opt/modules/hadoop-2.10.1</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure>

<ul>
<li>令环境变量生效：source /etc/profile</li>
<li>在命令行中输入：hadoop，如果能输出下列内容，就说明配置成功：</li>
</ul>
<img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201103200522625-1606575379995.png" alt="image-20201103200522625" style="zoom: 80%;">

<ul>
<li>配置hadoop的环境变量，需要配置hadoop-env.sh、mapred-env.sh、yarn-env.sh三个文件，在三个文件中分别加入：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export JAVA_HOME=/usr/java/jdk1.8.0_261-amd64/</span><br></pre></td></tr></table></figure>

<ul>
<li><p>配置HDFS</p>
<ul>
<li><p>修改配置文件conf/core-site.xml，添加以下内容：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 配置hdfs的主节点, hdfs://hostname:9000 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop01:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/opt/modules/hadoop-2.10.1/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>上述配置的解析如下：</p>
<p><strong>fs.defaultFS</strong>：HDFS的默认访问路径，也是NameNode的访问地址。</p>
<p><strong>hadoop.tmp.dir</strong>：Hadoop数据文件的存放目录，该参数不配置会默认指向/tmp目录，开机重启后会消失，容易导致hadoop数据丢失。</p>
<ul>
<li>修改配置文件conf/hdfs-site.xml，加入以下内容：</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--配置HDFS的冗余度(副本数,默认是3个)--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 配置不检查权限 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- namenode数据块的物理存储位置 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/opt/modules/hadoop-2.10.1/tmp/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- datanode数据块的物理存储位置 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/opt/modules/hadoop-2.10.1/tmp/dfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>dfs.replication</strong>：文件在HDFS系统中的副本数。</p>
<p><strong>dfs.permissions</strong>：是否对用户权限进行检查。</p>
<p><strong>dfs.namenode.name.dir</strong>：NameNode节点数据在本地文件系统的存放位置。</p>
<p><strong>dfs.datanode.data.dir</strong>：DataNode节点数据在本地文件系统的存放位置。</p>
<ul>
<li>修改slaves文件，配置DataNode节点，需要将所有的节点都加进去。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hadoop01</span><br><span class="line">hadoop02</span><br><span class="line">hadoop03</span><br></pre></td></tr></table></figure>

<ul>
<li>配置mapred-site.xml文件，添加以下内容：</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.application.classpath<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>配置yarn-site.xml文件，添加以下内容：</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- Site specific YARN configuration properties --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 配置resourcemanager所在节点与访问端口 hostname:8032 hostname通常为master节点--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop01:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>然后将配置好的hadoop发送到集群中的其他节点：</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp -r hadoop-2.10.1/ hadoop01@hadoop02:/opt/modules/</span><br><span class="line">scp -r hadoop-2.10.1/ hadoop01@hadoop03:/opt/modules/</span><br></pre></td></tr></table></figure>

<ul>
<li><p>hadoop在启动之前需要先格式化NameNode：hadoop namenode -format</p>
</li>
<li><p>在HADOOP_HOME目录下，输入：sbin/start-all.sh启动。</p>
</li>
<li><p>在命令行输入：jps，如果显示以下内容，说明启动成功：</p>
</li>
</ul>
<img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201103202921603-1606575387682.png" alt="image-20201103202921603" style="zoom:80%;">

<h5 id="安装ZooKeeper-3-6-2-2"><a href="#安装ZooKeeper-3-6-2-2" class="headerlink" title="安装ZooKeeper-3.6.2"></a>安装ZooKeeper-3.6.2</h5><ul>
<li>从apache官网下载一个ZooKeeper的稳定版本<a href="https://zookeeper.apache.org/releases.html%EF%BC%8C%E8%BF%99%E9%87%8C%E4%B8%8B%E8%BD%BDapache-zookeeper-3.6.2-bin.tar.gz">https://zookeeper.apache.org/releases.html，这里下载apache-zookeeper-3.6.2-bin.tar.gz</a></li>
<li>同样的，如果存在已经安装好的zookeeper版本，就将其删除。</li>
<li>将安装包解压到对应的安装目录：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf apache-zookeeper-3.6.2-bin.tar.gz -C /opt/modules/</span><br></pre></td></tr></table></figure>

<ul>
<li>配置ZooKeeper的环境变量</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export ZOOKEEPER_HOME=/opt/modules/apache-zookeeper-3.6.2-bin</span><br><span class="line">export PATH=$PATH:$ZOOKEEPER_HOME/bin:$ZOOKEEPER_HOME/conf</span><br></pre></td></tr></table></figure>

<ul>
<li>在ZooKeeper安装目录下的conf文件夹中创建zoo.cfg文件，并在其中添加下列内容</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 基本事件单元，用来指示一个心跳的时长，以毫秒为单位，默认是2000</span><br><span class="line">tickTime&#x3D;2000</span><br><span class="line"># 集群中的Follower服务器初始化连接leader服务器的最大等待心跳数</span><br><span class="line"># 默认为10，即经过10个心跳之后，follower仍然没有收到则意味着连接失败</span><br><span class="line">initLimit&#x3D;5</span><br><span class="line"># 集群中follower服务器与leader服务器之间发送消息和请求&#x2F;应答所能等待的最多心跳数</span><br><span class="line">syncLimit&#x3D;2</span><br><span class="line"># ZooKeeper数据文件的存储位置</span><br><span class="line">dataDir&#x3D;&#x2F;opt&#x2F;modules&#x2F;apache-zookeeper-3.6.2-bin&#x2F;data</span><br><span class="line"># ZooKeeper供客户端连接的端口，默认是2181</span><br><span class="line">clientPort&#x3D;2181</span><br><span class="line"># 标识不同的zookeeper服务器，host&#x2F;ip:leader port:选举port</span><br><span class="line">server.1&#x3D;hadoop01:2888:3888</span><br><span class="line">server.2&#x3D;hadoop02:2888:3888</span><br><span class="line">server.3&#x3D;hadoop03:2888:3888</span><br></pre></td></tr></table></figure>

<ul>
<li>配置好后，将zookeeper复制到其他节点上：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp -r apache-zookeeper-3.6.2-bin/ hadoop01@hadoop02:/opt/modules/</span><br><span class="line">scp -r apache-zookeeper-3.6.2-bin/ hadoop01@hadoop03:/opt/modules/</span><br></pre></td></tr></table></figure>

<ul>
<li>分别进入每台机子上的ZooKeeper的安装目录，然后再命令行输入：bin/zkServer.sh start</li>
<li>在命令行输入jps，会显示quorumpeermain。</li>
</ul>
<h5 id="安装Hbase-2-3-2-2"><a href="#安装Hbase-2-3-2-2" class="headerlink" title="安装Hbase-2.3.2"></a>安装Hbase-2.3.2</h5><ul>
<li>从apache官网上下载hbase-2.3.2的安装包<a href="http://hbase.apache.org/downloads.html%EF%BC%8C%E5%9C%A8%E6%8F%90%E4%BE%9B%E7%9A%84%E5%AE%89%E8%A3%85%E6%96%87%E4%BB%B6%E5%A4%B9%E9%87%8C%E5%B7%B2%E7%BB%8F%E6%9C%89%E4%BA%86%EF%BC%9Ahbase-2.3.2-bin.tar.gz%E3%80%82">http://hbase.apache.org/downloads.html，在提供的安装文件夹里已经有了：hbase-2.3.2-bin.tar.gz。</a></li>
<li>将其解压到对应的安装目录：tar -xzvf hbase-2.3.2-bin.tar.gz -C /opt/modules/</li>
<li>修改Hbase安装目录下的conf/hbase-site.xml文件，来指定Hbase和ZooKeeper的本地数据存储目录，默认是/tmp。</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Licensed to the Apache Software Foundation (ASF) under one</span></span><br><span class="line"><span class="comment"> * or more contributor license agreements.  See the NOTICE file</span></span><br><span class="line"><span class="comment"> * distributed with this work for additional information</span></span><br><span class="line"><span class="comment"> * regarding copyright ownership.  The ASF licenses this file</span></span><br><span class="line"><span class="comment"> * to you under the Apache License, Version 2.0 (the</span></span><br><span class="line"><span class="comment"> * &quot;License&quot;); you may not use this file except in compliance</span></span><br><span class="line"><span class="comment"> * with the License.  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *     http://www.apache.org/licenses/LICEANSE-2.0</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"> * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment"> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"> * See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"> * limitations under the License.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">    The following properties are set for running HBase as a single process on a</span></span><br><span class="line"><span class="comment">    developer workstation. With this configuration, HBase is running in</span></span><br><span class="line"><span class="comment">    &quot;stand-alone&quot; mode and without a distributed file system. In this mode, and</span></span><br><span class="line"><span class="comment">    without further configuration, HBase and ZooKeeper data are stored on the</span></span><br><span class="line"><span class="comment">    local filesystem, in a path under the value configured for `hbase.tmp.dir`.</span></span><br><span class="line"><span class="comment">    This value is overridden from its default value of `/tmp` because many</span></span><br><span class="line"><span class="comment">    systems clean `/tmp` on a regular basis. Instead, it points to a path within</span></span><br><span class="line"><span class="comment">    this HBase installation directory.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    Running against the `LocalFileSystem`, as opposed to a distributed</span></span><br><span class="line"><span class="comment">    filesystem, runs the risk of data integrity issues and data loss. Normally</span></span><br><span class="line"><span class="comment">    HBase will refuse to run in such an environment. Setting</span></span><br><span class="line"><span class="comment">    `hbase.unsafe.stream.capability.enforce` to `false` overrides this behavior,</span></span><br><span class="line"><span class="comment">    permitting operation. This configuration is for the developer workstation</span></span><br><span class="line"><span class="comment">    only and __should not be used in production!__</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    See also https://hbase.apache.org/book.html#standalone_dist</span></span><br><span class="line"><span class="comment">  --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 开启分布式模式  --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 存储目录 需要与HDFS NameNode端口一致--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop01:9000/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>The directory shared byregion servers.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 配置zookeeper监听端口 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.clientPort<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--  zookeeper节点列表 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop01,hadoop02,hadoop03<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--  zookeeper数据存放目录 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/modules/hbase-2.3.2/zkData<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- hbabse临时文件存放目录 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/modules/hbase-2.3.2/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>修改hbase安装目录下的conf/regionservers文件，去掉默认的localhost，添加集群中每个机子的hostname:</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hadoop01</span><br><span class="line">hadoop02</span><br><span class="line">hadoop03</span><br></pre></td></tr></table></figure>

<ul>
<li>将配置好的hbase复制到集群中的每个节点：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp -r hbase-2.3.2/ hadoop01@hadoop02:/opt/modules/</span><br><span class="line">scp -r hbase-2.3.2/ hadoop01@hadoop03:/opt/modules/</span><br></pre></td></tr></table></figure>

<ul>
<li>在hadoop01下启动Hbase服务，在Hbase安装目录下，运行以下指令：bin/start-hbase.sh</li>
<li>启动以后，在命令行输入：jps，会显示hmaster、hregionserver。</li>
</ul>
<h5 id="安装mysql-2"><a href="#安装mysql-2" class="headerlink" title="安装mysql"></a>安装mysql</h5><p>Hive的运行有内嵌、本地和远程模式，因为当前业务场景的问题，只需要本地模式即可，而本地模式需要依赖mysql。</p>
<ul>
<li>移除现有的mysql相关安装包：yum -y remove mysql*</li>
<li>下载mysql安装的yum release：wget <a href="http://repo.mysql.com/mysql-community-release-el7.rpm">http://repo.mysql.com/mysql-community-release-el7.rpm</a></li>
<li>使用rpm安装该依赖：rpm -ivh mysql-community-release-el7.rpm</li>
<li>使用yum安装mysql最新版本：yum -y install mysql-server</li>
<li>然后在命令行中输入下列指令，以开启mysql服务。</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl start mysqld   </span><br><span class="line">systemctl enable mysqld</span><br><span class="line">systemctl status mysqld</span><br></pre></td></tr></table></figure>

<ul>
<li>mysql刚安装好的时候，其密码是临时生成的，需要重新配置mysql的密码。</li>
</ul>
<p>通过下行指令可以得到临时生成的mysql密码，将其复制，记为temp password。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">grep &#x27;password&#x27; /var/log/mysqld.log|tail -n 1</span><br></pre></td></tr></table></figure>

<p>然后使用下行指令修改mysql密码为自己的：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysqladmin -uroot -p&quot;temp password&quot; password &quot;yours password&quot;</span><br></pre></td></tr></table></figure>

<p>使用自己的mysql登录密码登陆mysql：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysql -uroot -p&quot;yours password&quot;</span><br></pre></td></tr></table></figure>

<p>如果进入则说明登录成功：</p>
<img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201104110833100-1606575395672.png" alt="image-20201104110833100" style="zoom:80%;">

<ul>
<li>为了与hive联调，需要在mysql中创建一个叫做hive_db的表，用于存放Hive元数据信息，并且创建hive用户，为其赋予全局外部访问权限，下面是mysql的执行sql语句：</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> databse hive_db;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">user</span> hive <span class="keyword">IDENTIFIED</span> <span class="keyword">by</span> <span class="string">&#x27;hive&#x27;</span>;</span><br><span class="line"><span class="keyword">grant</span> <span class="keyword">all</span> <span class="keyword">privileges</span> <span class="keyword">on</span> hive_db.* <span class="keyword">to</span> hive@<span class="string">&#x27;%&#x27;</span> <span class="keyword">with</span> <span class="keyword">grant</span> <span class="keyword">option</span>;</span><br><span class="line"><span class="keyword">flush</span> <span class="keyword">privileges</span>;</span><br></pre></td></tr></table></figure>

<h5 id="安装hive-2-3-7-2"><a href="#安装hive-2-3-7-2" class="headerlink" title="安装hive-2.3.7"></a>安装hive-2.3.7</h5><p>Hive不需要安装集群模式，只需要在其中一个节点安装即可，这里选择hadoop01作为hive的安装节点。</p>
<ul>
<li>从apache官网上下载hive-2.3.7的安装包：<a href="https://mirrors.bfsu.edu.cn/apache/hive/hive-2.3.7/%EF%BC%8C%E5%9C%A8%E6%8F%90%E4%BE%9B%E7%9A%84%E5%AE%89%E8%A3%85%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%AD%E5%B7%B2%E7%BB%8F%E5%8C%85%E5%90%AB%E8%AF%A5%E5%AE%89%E8%A3%85%E5%8C%85%EF%BC%9Aapache-hive-2.3.7-bin.tar.gz%E3%80%82">https://mirrors.bfsu.edu.cn/apache/hive/hive-2.3.7/，在提供的安装文件夹中已经包含该安装包：apache-hive-2.3.7-bin.tar.gz。</a></li>
<li>解压hive安装包到/opt/modules/：tar -xzvf apache-hive-2.3.7-bin.tar.gz -C /opt/modules/</li>
<li>配置环境变量，在/etc/profile中添加以下内容：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export HIVE_HOME=/opt/modules/apache-hive-2.3.7-bin</span><br><span class="line">export PATH=$PATH:$HIVE_HOME/bin</span><br></pre></td></tr></table></figure>

<p>然后执行：source /etc/profile使得配置生效。</p>
<ul>
<li>在命令行输入：hive –version，如果能输出hive的版本信息，则说明安装成功。</li>
</ul>
<img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201104143049745-1606575398607.png" alt="image-20201104143049745" style="zoom:80%;">

<ul>
<li>创建hive数据仓库目录</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hadoop fs -mkdir	 /tmp</span><br><span class="line">hadoop fs -mkdir -p  /user/hive/warehouse</span><br><span class="line">hadoop fs -chmod g+w /tmp</span><br><span class="line">hadoop fs -chmod g+w /user/hive/warehouse</span><br></pre></td></tr></table></figure>

<p>/tmp：hive任务在HDFS中的缓存目录。</p>
<p>/user/hive/warehouse：hive数据仓库目录，用于存储hive创建的数据库。</p>
<p>这两个路径可以在配置文件中更改。</p>
<ul>
<li>上传java连接mysql的驱动包mysql-connector-java-8.0.22.jar到$HIVE_HOME/lib中。</li>
<li>修改hive的配置文件</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">   Licensed to the Apache Software Foundation (ASF) under one or more</span></span><br><span class="line"><span class="comment">   contributor license agreements.  See the NOTICE file distributed with</span></span><br><span class="line"><span class="comment">   this work for additional information regarding copyright ownership.</span></span><br><span class="line"><span class="comment">   The ASF licenses this file to You under the Apache License, Version 2.0</span></span><br><span class="line"><span class="comment">   (the &quot;License&quot;); you may not use this file except in compliance with</span></span><br><span class="line"><span class="comment">   the License.  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">       http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">   Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">   distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">   See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">   limitations under the License.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- WARNING!!! This file is auto generated for documentation purposes ONLY! --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- WARNING!!! Any changes you make to this file will be ignored by Hive.   --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- WARNING!!! You must make your changes in hive-site.xml instead.         --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- Hive Execution Parameters --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- mysql数据库连接信息 --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 采取本地模式存储hive元数据库 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.local<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- mysql连接地址, 此处连接本地mysql数据库, 可以更改为连接远程mysql数据库 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://localhost:3306/hive_db?createDatabaseIfNotExist=true<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 连接mysql的驱动类 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- mysql用户名 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- mysql登录密码 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>P@ssw0rd<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span>   </span><br><span class="line">  <span class="comment">&lt;!-- hive数据库在hdfs中的存放位置 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>location of default database for the warehouse<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line">  <span class="comment">&lt;!-- hive本地缓存目录 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.exec.local.scratchdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/tmp/hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Local scratch space for Hive jobs<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- hive在hdfs中的缓存目录 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.exec.scratchdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/tmp/hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>HDFS root scratch dir for Hive jobs which gets created with write all (733) permission. For each connecting user, an HDFS scratch dir: $&#123;hive.exec.scratchdir&#125;/<span class="symbol">&amp;lt;</span>username<span class="symbol">&amp;gt;</span> is created, with $&#123;hive.scratch.dir.permission&#125;.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 从远程文件系统中添加资源的本地临时目录 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.downloaded.resources.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/tmp/hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Temporary local directory for added resources in the remote file system.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- hive运行时的结构化日志目录 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.querylog.location<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/tmp/hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Location of Hive run time structured log file<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 日志功能开启时, 存储操作日志的最高级目录 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.logging.operation.log.location<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/tmp/hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Top level directory where operation logs are stored if logging functionality is enabled<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>初始化元数据库：$HIVE_HOME/bin/schematool -dbType mysql -initSchema</li>
</ul>
<img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201104145800066-1606575402964.png" alt="image-20201104145800066" style="zoom:80%;">

<p>输出上述信息说明初始化数据成功。</p>
<ul>
<li>然后命令行输入hive，测试能否正常运行hive。</li>
</ul>
<p><img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201104152203181.png" alt="image-20201104152203181"></p>
<p>有上述信息说明安装成功。</p>
<h5 id="hive整合hbase-2"><a href="#hive整合hbase-2" class="headerlink" title="hive整合hbase"></a>hive整合hbase</h5><p>在hive安装目录下的conf/hive-site.xml文件中添加下列内容：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 配置zookeeper集群访问地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop01:2181,hadoop02:2181,hadoop03:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 配置依赖的hbase、zookeeper的jar文件 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.aux.jars.path<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line">  file:///opt/modules/hbase-2.3.2/lib/hbase-common-2.3.2.jar,</span><br><span class="line">  file:///opt/modules/hbase-2.3.2/lib/hbase-client-2.3.2.jar,</span><br><span class="line">  file:///opt/modules/hbase-2.3.2/lib/hbase-server-2.3.2.jar,</span><br><span class="line">  file:///opt/modules/hbase-2.3.2/lib/hbase-hadoop2-compat-2.3.2.jar,</span><br><span class="line">  file:///opt/modules/hbase-2.3.2/lib/netty-all-4.0.23.Final.jar,</span><br><span class="line">  file:///opt/modules/hbase-2.3.2/lib/hbase-protocol-2.3.2.jar,</span><br><span class="line">  file:///opt/modules/apache-zookeeper-3.6.2-bin/lib/zookeeper-3.6.2.jar,</span><br><span class="line">  <span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.enable.doAs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>Setting this property to true will have HiveServer2 execute Hive operations as the user making the calls to it.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>启动hiveserver2服务：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hive --service hiveserver2 &amp;</span><br></pre></td></tr></table></figure>

<p><img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201105103548823.png" alt="image-20201105103548823"></p>
<ul>
<li>另起一个shell，这里采用beeline的方式连接hive：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">beeline</span><br><span class="line">!connect jdbc:hive2://hadoop01:10000</span><br></pre></td></tr></table></figure>

<p>如果显示下面结果就说明运行成功：</p>
<img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201105103246089-1606575412056.png" alt="image-20201105103246089" style="zoom:80%;">

<ul>
<li>到此，单机安装Hadoop-2.10.1+Hbase-2.3.2+Hive-2.3.7完毕，下面测试由hive直接创建hbase表：</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> hive_student(<span class="keyword">id</span> <span class="built_in">INT</span>, <span class="keyword">name</span> <span class="keyword">STRING</span>) <span class="keyword">STORED</span> <span class="keyword">BY</span> <span class="string">&#x27;org.apache.hadoop.hive.hbase.HBaseStorageHandler&#x27;</span> <span class="keyword">WITH</span> SERDEPROPERTIES (<span class="string">&quot;hbase.columns.mapping&quot;</span> = <span class="string">&quot;:key,cf1:name&quot;</span>) TBLPROPERTIES (<span class="string">&quot;hbase.table.name&quot;</span> = <span class="string">&quot;hive_student&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>如果在hiveserver2那个shell框里面显示下列结果，说明创建成功：</p>
<p><img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201105103851443.png" alt="image-20201105103851443"></p>
<p>登陆hbase的web界面，可以看到创建的数据库表：</p>
<p><img src="/2020/11/28/Hadoop-2-10-1-ZooKeeper-3-6-2-Hbase-2-3-2-Hive-2-3-7%E5%AE%89%E8%A3%85/image-20201105103935523.png" alt="image-20201105103935523"></p>
]]></content>
      <tags>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2020/11/28/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
</search>
